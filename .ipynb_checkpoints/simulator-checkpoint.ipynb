{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import time\n",
    "import requests\n",
    "import os\n",
    "import numpy as np\n",
    "import xlsxwriter\n",
    "from abc import ABCMeta, abstractmethod\n",
    "from Queue import Queue\n",
    "from collections import deque\n",
    "import getpass\n",
    "import pandas.io.formats.excel\n",
    "from matplotlib import rc\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class SimulationEnv(object):\n",
    "    \n",
    "    loggables = ['positions']\n",
    "    \n",
    "    def __init__(self, wealth, assets, \n",
    "                 path_to_data, start_date, end_date,\n",
    "                 agent_type, expert_type, reinvest, max_assets=100):\n",
    "\n",
    "        self.init_wealth = wealth\n",
    "        self.wealth = wealth\n",
    "        self.assets = assets\n",
    "        self.agent_type = agent_type\n",
    "        self.expert_type = expert_type\n",
    "        self.path_to_data = path_to_data\n",
    "        self.reinvest = reinvest\n",
    "        self.max_assets = max_assets\n",
    "        self.start_date = start_date\n",
    "        self.end_date = end_date\n",
    "        \n",
    "        return\n",
    "    \n",
    "    ## To be called before running a simulation - initialize experts, agents, and initial position, etc.\n",
    "    def setup_params(self, agent_args={}, expert_args={}):\n",
    "    \n",
    "        stdevs = {}\n",
    "        for f in os.listdir(self.path_to_data):\n",
    "            df = pd.read_csv(self.path_to_data+f)\n",
    "            df = df[df[\"date\"] < self.end_date]\n",
    "            df[\"return\"] = (df[\"adj_close\"] - df[\"adj_close\"].shift(1))/df[\"adj_close\"].shift(1)\n",
    "            stdevs[f] = df[\"return\"].std()\n",
    "            self.assets = [f.split(\".\")[0].upper() for f in sorted(stdevs, key=stdevs.get, reverse=True)[:self.max_assets]]\n",
    "        \n",
    "        print self.assets\n",
    "        \n",
    "        self.experts = [self.expert_type(a, self.path_to_data, self.start_date, self.end_date, **expert_args) for a in self.assets]\n",
    "        self.agent = self.agent_type(self.experts, **agent_args)\n",
    "        self.positions = np.array([weight * self.wealth for weight in self.agent.weights])\n",
    "        \n",
    "        return\n",
    "        \n",
    "    ## Run simulation\n",
    "    def run(self, log=False, logpath=os.getcwd()):\n",
    "        \n",
    "        ## Start period counter and log\n",
    "        self.period = 1\n",
    "        self.finallog = []\n",
    "        self.log = log\n",
    "        self.logpath = logpath\n",
    "        \n",
    "        ## Warmup period: \n",
    "        ## i.e. for strategies involving moving average indicators, wait until we have enough data to calculate MA\n",
    "        for expert in self.agent.experts:\n",
    "            expert.warmup()\n",
    "        \n",
    "        ## Simulation: Go until data iterators reach the end\n",
    "        print \"Initial weights:\"\n",
    "        print np.array([weight for weight in self.agent.weights])\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                print \"PERIOD {}\".format(self.period)\n",
    "                print \"dates:\"\n",
    "                dates = [e.current_date for e in self.agent.experts]\n",
    "                print list(set(dates))\n",
    "                ## NEED TO MAKE THIS TRUE\n",
    "                ## assert len(set(dates)) == 1\n",
    "              \n",
    "\n",
    "\n",
    "                print \"---------------------\"\n",
    "                ## Log this period\n",
    "                if log:\n",
    "                    self.logperiod()\n",
    "                    \n",
    "                ## Update experts with last period's rewards\n",
    "                for i, expert in enumerate(self.agent.experts):\n",
    "                    expert.update()\n",
    "\n",
    "                ## Update agent accordingly (i.e. for Hedge, update weights according to each expert's reward in the last period)\n",
    "                self.agent.update()\n",
    "                           \n",
    "                ## Rewards accrue to agent\n",
    "                self.positions = self.positions * (1 + self.agent.returns)\n",
    "                self.wealth = np.sum(self.positions)\n",
    "                \n",
    "                ## Rebalance according to new, updated weights\n",
    "                ## TODO: only allow non-fractional shares to be purchased (?)\n",
    "                if np.sum(self.agent.weights) == 1:\n",
    "                    self.positions = np.array([weight * self.wealth for weight in self.agent.weights])\n",
    "                \n",
    "#                 print \"weights:\"\n",
    "#                 print np.array([weight for weight in self.agent.weights])\n",
    "\n",
    "#                 print \"rewards:\"\n",
    "#                 print np.array([r for r in self.agent.rewards])\n",
    "#                 print \"returns:\"\n",
    "#                 print np.array([r for r in self.agent.returns])\n",
    "                \n",
    "#                 print \"positions:\"\n",
    "#                 print np.array([weight * self.wealth for weight in self.agent.weights])\n",
    "#                 print \"positions invested:\"\n",
    "#                 positions_invested = np.array([e.pick for e in self.agent.experts])*self.positions\n",
    "#                 print positions_invested\n",
    "#                 if self.reinvest and np.any(positions_invested):\n",
    "#                     uninvested_wealth = self.wealth - np.sum(positions_invested)\n",
    "#                     print \"Need to reallocate {} cash amongst experts that are investing\".format(uninvested_wealth)\n",
    "#                     print \"Total wealth:\"\n",
    "#                     print self.wealth\n",
    "#                     print \"Reinvestments:\"\n",
    "#                     print uninvested_wealth * positions_invested/np.sum(positions_invested)\n",
    "#                     print \"Final position\"\n",
    "#                     self.positions = uninvested_wealth * positions_invested/np.sum(positions_invested) + positions_invested\n",
    "#                     print self.positions\n",
    "#                     new_wealth = np.sum(self.positions)\n",
    "#                     assert(new_wealth-self.wealth <= 0.00001)\n",
    "                \n",
    "#                 print \"---------------------\"\n",
    "#                 print \"\\n\\n\"\n",
    "                \n",
    "                \n",
    "                ## Advance period\n",
    "                self.period += 1\n",
    "                \n",
    "            except StopIteration:\n",
    "                break\n",
    "        \n",
    "        ## Write the log file\n",
    "        if log:\n",
    "            self.savelog()\n",
    "\n",
    "    def logperiod(self):\n",
    "        row = [self.period] + [self.wealth]\n",
    "        nrow = []\n",
    "        for loggable in (self.loggables):\n",
    "            if getattr(self,loggable) is None:\n",
    "                nrow += [None] * len(self.experts)\n",
    "            else:\n",
    "                nrow += getattr(self,loggable).tolist()\n",
    "        arow = []\n",
    "        for loggable in (self.agent_type.loggables):\n",
    "            if getattr(self.agent,loggable) is None:\n",
    "                arow += [None] * len(self.experts)\n",
    "            else:\n",
    "                arow += getattr(self.agent,loggable).tolist()\n",
    "        erow = []\n",
    "        for loggable in (self.expert_type.loggables):\n",
    "            if [getattr(e,loggable) for e in self.experts] is None:\n",
    "                erow += [None] * len(self.experts)\n",
    "            else:\n",
    "                erow += [getattr(e,loggable) for e in self.experts]\n",
    "        row += nrow + arow + erow\n",
    "        self.finallog.append(row)\n",
    "    \n",
    "    def savelog(self):\n",
    "        # Set up log file structure\n",
    "        runtime = datetime.datetime.now()\n",
    "        runuser = getpass.getuser()\n",
    "        logname = runuser + \"_\" + runtime.strftime('%Y-%m-%d_%H-%M-%S')\n",
    "        if not os.path.exists(os.path.join(self.logpath, logname)):\n",
    "            os.makedirs(os.path.join(self.logpath, logname))\n",
    "            os.makedirs(os.path.join(self.logpath, logname, 'plots'))\n",
    "        \n",
    "        # Create dataframe from log\n",
    "        col = ['period', 'wealth'] + \\\n",
    "            [x+'.'+y for x in self.loggables for y in self.assets] + \\\n",
    "            [x+'.'+y for x in self.agent_type.loggables for y in self.assets] + \\\n",
    "            [x+'.'+y for x in self.expert_type.loggables for y in self.assets]\n",
    "        df = pd.DataFrame(self.finallog, columns=col)\n",
    "        df.set_index('period', inplace=True)\n",
    "        \n",
    "        # Write xlsx of log data\n",
    "        writer = pd.ExcelWriter(os.path.join(self.logpath, logname, logname+'.xlsx'), engine='xlsxwriter')\n",
    "        pd.io.formats.excel.header_style = None\n",
    "        df.to_excel(writer,'run_log')\n",
    "        \n",
    "        workbook  = writer.book\n",
    "        worksheet = writer.sheets['run_log']\n",
    "        \n",
    "        header_format = workbook.add_format({'bold': True,'text_wrap': True})\n",
    "        worksheet.set_row(0, None, header_format)\n",
    "        writer.save()\n",
    "        \n",
    "        # Set up matplotlib. Loop through loggables and save a plot with and without legend for each.\n",
    "        rc('font', family = 'serif', serif = 'cmr10')\n",
    "        plots = ['wealth'] + self.loggables + self.agent_type.loggables + self.expert_type.loggables\n",
    "        \n",
    "        for p in plots:\n",
    "            for legend in [True, False]:\n",
    "                plotdf = df.filter(regex='period|'+p)\n",
    "                plotlab = [l.split(p+'.',1)[1] if l != 'wealth' else l.title() for l in list(plotdf.columns.values)]\n",
    "                plt.plot(plotdf)\n",
    "                plt.ylabel(p.title())\n",
    "                plt.xlabel('Round')\n",
    "                plt.ticklabel_format(useOffset=False)\n",
    "                if legend:\n",
    "                    plt.legend(plotlab, loc=9, bbox_to_anchor=(0.5, -0.15), ncol=4)\n",
    "                    plt.savefig(os.path.join(self.logpath, logname, 'plots', p+'_legend.png'), bbox_inches='tight', dpi=300)\n",
    "                else:\n",
    "                    plt.savefig(os.path.join(self.logpath, logname, 'plots', p+'.png'), bbox_inches='tight', dpi=300)\n",
    "                plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base classes\n",
    "\n",
    "Base classes for agents and experts to be implemented by us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class Agent(object):\n",
    "    __metaclass__ =ABCMeta\n",
    "    \n",
    "    @abstractmethod\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def update(self):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def act(self):\n",
    "        pass\n",
    "    \n",
    "class Expert(object):\n",
    "    __metaclass__=ABCMeta\n",
    "    \n",
    "    ## Required parameters for initializing experts\n",
    "    @abstractmethod\n",
    "    def __init__(self, name, path_to_data, start_date, end_date):\n",
    "        self.reward = 0.\n",
    "        self.pick = False ## Need to activate experts in child classes\n",
    "        self.data = pd.read_csv(path_to_data + name + \".csv\", iterator=True, chunksize=1)\n",
    "        self.current_date = datetime.strptime(\"1000-01-01\", \"%Y-%m-%d\")\n",
    "        self.start_date = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "        self.end_date = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "        while self.current_date < self.start_date:\n",
    "            self.last_row = self.data.get_chunk(1)\n",
    "            self.last_price = float(self.last_row[\"adj_close\"])\n",
    "            self.current_date = datetime.strptime(self.last_row[\"date\"].item(), \"%Y-%m-%d\")\n",
    "        \n",
    "    @abstractmethod\n",
    "    def update(self):\n",
    "        pass\n",
    "    \n",
    "class Context(object):\n",
    "    __metaclass__=ABCMeta\n",
    "    \n",
    "    @abstractmethod\n",
    "    def __init__(self, context_data):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def observe(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agents\n",
    "\n",
    "Implementations of different online portfolio selection algorithms\n",
    "* Exponential Gradient\n",
    "* Exponential Gradient (recent history only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## EG. (http://www.cis.upenn.edu/~mkearns/finread/helmbold98line.pdf)\n",
    "class EG(Agent):\n",
    "    \n",
    "    loggables = ['returns','rewards','weights']\n",
    "    \n",
    "    ## Initialize with a set of experts\n",
    "    def __init__(self, experts, eta):\n",
    "        self.eta = eta\n",
    "        self.experts = experts\n",
    "        self.weights = np.ones(len(self.experts))/len(self.experts)\n",
    "        self.rewards = None\n",
    "        self.returns = None\n",
    "        return\n",
    "    \n",
    "    ## Update the agent's rewards and its weights for each expert\n",
    "    def update(self):\n",
    "        self.rewards = np.asarray([e.reward for e in self.experts])\n",
    "        self.returns = np.asarray([e.returns for e in self.experts])\n",
    "        multipliers = np.exp(self.eta * self.rewards/np.sum(self.weights * self.rewards))\n",
    "        self.weights = (self.weights * multipliers)/ np.sum(self.weights * multipliers)\n",
    "        self.weights = np.nan_to_num(self.weights)\n",
    "\n",
    "        return\n",
    "    \n",
    "    def act(self):\n",
    "        return self.weights\n",
    "\n",
    "\n",
    "class EGRecent(Agent):\n",
    "    \n",
    "    loggables = ['returns','rewards','weights']\n",
    "    \n",
    "    ## Initialize with a set of experts\n",
    "    def __init__(self, experts, eta, n):\n",
    "        self.eta = eta\n",
    "        self.experts = experts\n",
    "        #self.weights = Queue(maxsize=n)\n",
    "        self.weights = np.ones(len(self.experts))/len(self.experts)\n",
    "        self.rewards = deque(maxlen=n)\n",
    "        self.returns = None\n",
    "        self.t = 0\n",
    "        self.n = n\n",
    "        #self.rewards = None\n",
    "        #self.returns = None\n",
    "        return\n",
    "    \n",
    "    ## Update the agent's rewards and its weights for each expert\n",
    "    def update(self):\n",
    "           \n",
    "        self.rewards.append(np.asarray([e.reward for e in self.experts]))\n",
    "        self.returns = np.asarray([e.returns for e in self.experts])\n",
    "        \n",
    "        self.weights = np.ones(len(self.experts))/len(self.experts)\n",
    "        #print self.t\n",
    "        #print len(self.rewards)\n",
    "        for rewards in self.rewards:\n",
    "            rewards = np.asarray(rewards)\n",
    "            multipliers = np.exp(self.eta * rewards/np.sum(self.weights * rewards))\n",
    "            self.weights = (self.weights * multipliers)/ np.sum(self.weights * multipliers)\n",
    "            self.weights = np.nan_to_num(self.weights)\n",
    "        self.t += 1\n",
    "        #print self.t\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def act(self):\n",
    "        return self.weights\n",
    "    \n",
    "      \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More agents to serve as naive/benchmark portfolio allocation algorithms:\n",
    "* Equal-weighted buy and hold\n",
    "* Market-weighted buy and hold\n",
    "* Constantly rebalanced portfolio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Some other examples of agents to use as benchmarks \n",
    "\n",
    "class ConstantRebalancer(Agent):\n",
    "    \n",
    "    loggables = ['rewards','weights']\n",
    "    \n",
    "    def __init__(self, experts):\n",
    "        self.experts = experts\n",
    "        self.weights = np.ones(len(self.experts))/len(self.experts)\n",
    "        self.rewards = None\n",
    "        return\n",
    "    \n",
    "    def update(self):\n",
    "        self.rewards = np.asarray([e.reward for e in self.experts])\n",
    "        self.returns = self.rewards - 1.\n",
    "        return\n",
    "    \n",
    "    def act(self):\n",
    "        return self.weights\n",
    "    \n",
    "## TODO\n",
    "class WeightedBuyHold(Agent):\n",
    "    \n",
    "    def __init__(self):\n",
    "        return\n",
    "    \n",
    "    def update(self):\n",
    "        return\n",
    "    \n",
    "    def act(self):\n",
    "        return\n",
    "    \n",
    "\n",
    "## to be used with \"Dummy\" Expert for each stock\n",
    "class NaiveBuyHold(Agent):\n",
    "    \n",
    "    def __init__(self, experts):\n",
    "        self.experts = experts\n",
    "        self.weights = np.ones(len(self.experts))/len(self.experts)\n",
    "        self.rewards = None\n",
    "        return\n",
    "    \n",
    "    def update(self):\n",
    "        self.rewards = np.asarray([e.reward for e in self.experts])\n",
    "        self.returns = self.rewards - 1.\n",
    "        self.weights = np.multiply(self.weights, self.rewards)\n",
    "        self.weights = np.divide(self.weights, np.sum(self.weights))\n",
    "        assert((np.sum(self.weights) - 1.) <= 0.00001)\n",
    "        return\n",
    "    \n",
    "    def act(self):\n",
    "        return self.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experts\n",
    "\n",
    "* Dummy\n",
    "* Mean Reversion\n",
    "* Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "## Dummy expert that always pick the same asset\n",
    "class Dummy(Expert):\n",
    "    \n",
    "    loggables = ['reward']\n",
    "    \n",
    "    ## Expert has a reward associated with its pick\n",
    "    def __init__(self, name, path_to_data, start_date, end_date):\n",
    "        super(Dummy, self).__init__(name, path_to_data, start_date, end_date)\n",
    "        self.pick = True\n",
    "        return\n",
    "    \n",
    "    ## Expert updates its reward \n",
    "    def update(self):\n",
    "        self.last_row = self.data.get_chunk(1)\n",
    "        self.current_date = datetime.strptime(self.last_row[\"date\"].item(), \"%Y-%m-%d\")\n",
    "        \n",
    "        if self.current_date > self.end_date:\n",
    "            raise StopIteration\n",
    "            \n",
    "        current_price = float(self.last_row[\"adj_close\"])\n",
    "        self.reward = current_price/self.last_price\n",
    "        self.returns = self.reward - 1.\n",
    "        self.last_price = current_price\n",
    "        return\n",
    "    \n",
    "    def warmup(self):\n",
    "        pass\n",
    "    \n",
    "\n",
    "class MeanReversion(Expert):\n",
    "    \n",
    "    loggables = ['avg','std']\n",
    "    \n",
    "    def __init__(self, name, path_to_data, start_date, end_date, window_size, threshold):\n",
    "        super(MeanReversion, self).__init__(name, path_to_data, start_date, end_date)\n",
    "        self.window_size = window_size\n",
    "        self.avg = 0.0\n",
    "        self.std = 0.0\n",
    "        self.threshold = threshold\n",
    "        self.last_n_prices = Queue(maxsize=10)\n",
    "        self.returns = 0.\n",
    "\n",
    "        return\n",
    "    \n",
    "    def warmup(self):\n",
    "        n = 1\n",
    "        while n <= self.window_size:\n",
    "            self.last_n_prices.put(self.last_price)\n",
    "            \n",
    "            self.last_row = self.data.get_chunk(1)\n",
    "            self.current_date = datetime.strptime(self.last_row[\"date\"].item(), \"%Y-%m-%d\")\n",
    "\n",
    "            self.last_price = float(self.last_row[\"adj_close\"])\n",
    "            n += 1\n",
    "        return\n",
    "        \n",
    "    def update(self):\n",
    "        _ = self.last_n_prices.get()\n",
    "        \n",
    "        self.last_n_prices.put(self.last_price)\n",
    "        self.avg = np.mean(list(self.last_n_prices.queue))\n",
    "        self.std = np.std(list(self.last_n_prices.queue))\n",
    "        \n",
    "        self.last_row = self.data.get_chunk(1)\n",
    "        self.current_date = datetime.strptime(self.last_row[\"date\"].item(), \"%Y-%m-%d\")\n",
    "        \n",
    "        if self.current_date > self.end_date:\n",
    "            raise StopIteration\n",
    "            \n",
    "        current_price = float(self.last_row[\"adj_close\"])\n",
    "        \n",
    "        ## If self.pick is True, we bought the stock and our reward is whatever the return was in the last period\n",
    "        if self.pick:\n",
    "            self.reward = current_price/self.last_price\n",
    "            self.returns = self.reward - 1.\n",
    "        else:\n",
    "            self.reward = self.last_price/current_price\n",
    "            self.returns = 0\n",
    "            \n",
    "        self.last_price = current_price\n",
    "\n",
    "        if self.last_price <= self.avg - self.threshold * self.std:\n",
    "            self.pick = True\n",
    "        else:\n",
    "            self.pick = False\n",
    "\n",
    "        return\n",
    "\n",
    "    \n",
    "# class Momentum(Expert):\n",
    "    \n",
    "#     loggables = ['avg','std']\n",
    "    \n",
    "#     def __init__(self, name, path_to_data, window_size, threshold):\n",
    "#         self.reward = 0.\n",
    "#         self.pick = False\n",
    "#         self.data = pd.read_csv(path_to_data + name + \".csv\", iterator=True, chunksize=1)\n",
    "#         self.last_price = float(self.data.get_chunk(1)[\"adj_close\"])\n",
    "#         self.window_size = window_size\n",
    "#         self.avg = 0.0\n",
    "#         self.std = 0.0\n",
    "#         self.threshold = threshold\n",
    "#         self.last_n_prices = Queue(maxsize=10)\n",
    "#         self.returns = 0.\n",
    "#         return\n",
    "    \n",
    "#     def warmup(self):\n",
    "#         n = 1\n",
    "#         while n <= self.window_size:\n",
    "#             self.last_n_prices.put(self.last_price)\n",
    "#             self.last_price = float(self.data.get_chunk(1)[\"adj_close\"])\n",
    "#             n += 1\n",
    "#         return\n",
    "        \n",
    "#     def update(self):\n",
    "#         _ = self.last_n_prices.get()\n",
    "            \n",
    "#         self.last_n_prices.put(self.last_price)\n",
    "#         self.avg = np.mean(list(self.last_n_prices.queue))\n",
    "#         self.std = np.std(list(self.last_n_prices.queue))\n",
    "        \n",
    "#         current_price = float(self.data.get_chunk(1)[\"adj_close\"])\n",
    "\n",
    "#         ## If self.pick is True, we bought the stock and our reward is whatever the return was in the last period\n",
    "#         if self.pick:\n",
    "#             self.reward = current_price/self.last_price\n",
    "#             self.returns = self.reward - 1.\n",
    "#         else:\n",
    "#             self.reward = -current_price/self.last_price\n",
    "#             self.returns = 0\n",
    "#         self.last_price = current_price\n",
    "\n",
    "#         if self.last_price >= self.avg - self.threshold * self.std:\n",
    "#             self.pick = True\n",
    "#         else:\n",
    "#             self.pick = False\n",
    "\n",
    "#         return\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GridSearch(Agent, Expert, reinvest=False, full_data=False, agent_args=[], expert_args=[]):\n",
    "    ## Run simulation \n",
    "    start = time.time()\n",
    "    if full_data:\n",
    "        data = \"data/djia_20000101_20171101/\"\n",
    "        start_date = \"2000-01-01\"\n",
    "        year = 17.\n",
    "    else:\n",
    "        data = \"data/djia_20150101_20171101/\"\n",
    "        start_date = \"2015-01-01\"\n",
    "        year = 2.\n",
    "    best_wealth = 0\n",
    "    best_params = {}\n",
    "    for agent_arguments in agent_args:\n",
    "        for expert_arguments in expert_args:\n",
    "            \n",
    "            s = SimulationEnv(\n",
    "                initial_wealth, \n",
    "                stocks, \n",
    "                data, \n",
    "                start_date,\n",
    "                \"2017-11-01\", \n",
    "                Agent, \n",
    "                Expert, \n",
    "                reinvest\n",
    "            )\n",
    "            s.setup_params(\n",
    "                agent_args=agent_arguments,\n",
    "                expert_args=expert_arguments\n",
    "            )\n",
    "            s.run()\n",
    "\n",
    "            years = year + 11./12\n",
    "            ar = ((s.wealth)/initial_wealth)**(1/years) - 1\n",
    "            end = time.time()\n",
    "\n",
    "            if s.wealth > best_wealth:\n",
    "                best_wealth = s.wealth\n",
    "                best_params = {\n",
    "                    \"agent_args\": agent_arguments,\n",
    "                    \"expert_args\": expert_arguments,\n",
    "                    \"Initial wealth\": initial_wealth,\n",
    "                    \"Final wealth\": s.wealth,\n",
    "                    \"Annualized return\": ar,\n",
    "                    \"Time\": int(end-start),\n",
    "                }\n",
    "    print(\"Best params:\", best_params)\n",
    "    \n",
    "#GridSearch(ConstantRebalancer, Dummy, reinvest=True, full_data=False, agent_args=[{}], expert_args=[{}])\n",
    "#GridSearch(EG, Dummy, reinvest=True, full_data=False, agent_args=[{\"eta\":-0.01},{\"eta\":-0.005}], expert_args=[{}])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "  \n",
    "class VolContext(Context):\n",
    "    \n",
    "    def __init__(self, data_file, threshold):\n",
    "        self.data = pd.read_csv(data_file, iterator=True, chunksize=1)\n",
    "        self.threshold = threshold\n",
    "        self.contexts = [\"HighVol\", \"LowVol\"]\n",
    "        return\n",
    "    \n",
    "    # Returns a string giving the name of the context\n",
    "    def observe(self):\n",
    "        if float(self.data.get_chunk(1)[\"adj_close\"]) > self.threshold:\n",
    "            return self.contexts[0]\n",
    "        else:\n",
    "            return self.contexts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stocks = ['AAPL', 'AXP', 'BA', 'CAT', 'CSCO', 'CVX', 'DD', 'DIS', 'GE',\n",
    " 'GS', 'HD', 'IBM', 'INTC', 'JNJ', 'JPM', 'KO', 'MCD', 'MMM', \n",
    "'MRK', 'MSFT', 'NKE', 'PFE', 'PG', 'TRV', 'UNH', 'UTX', 'VZ', 'WMT', 'XOM']\n",
    "stocks = [stock.lower() for stock in stocks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "initial_wealth = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Run simulation where constantly rebalance investments\n",
    "start = time.time()\n",
    "s = SimulationEnv(1., stocks, \"data/djia_20150101_20171101/\", \"2016-01-01\", \"2016-12-31\", EG, Dummy, False, max_assets=2)\n",
    "s.setup_params(agent_args={\"eta\": 0.01})\n",
    "s.run()\n",
    "\n",
    "years = 2. + 11./12\n",
    "ar = ((s.wealth)/initial_wealth)**(1/years) - 1\n",
    "end = time.time()\n",
    "\n",
    "print(\"Initial wealth: ${}\".format(initial_wealth))\n",
    "print(\"Final wealth: ${}\".format(s.wealth))\n",
    "print(\"Annualized return: {}\".format(ar))\n",
    "print(\"Time: {}s\".format(int(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial wealth: $1.0\n",
      "Final wealth: $3.99557828344\n",
      "Annualized return: 0.0803800058262\n",
      "Time: 111s\n"
     ]
    }
   ],
   "source": [
    "# Run simulation with sophisticated experts and fully invested wealth\n",
    "start = time.time()\n",
    "s = SimulationEnv(1., stocks, \"data/djia_20000101_20171101/\", \"2000-01-01\", \"2017-11-01\", EG, MeanReversion, reinvest=True, max_assets=15)\n",
    "s.setup_params(\n",
    "    agent_args={\"eta\": 0.01}, \n",
    "    expert_args={\"window_size\": 10, \"threshold\": .5})\n",
    "s.run()\n",
    "\n",
    "years = 17. + 11./12\n",
    "ar = ((s.wealth)/initial_wealth)**(1/years) - 1\n",
    "end = time.time()\n",
    "\n",
    "print(\"Initial wealth: ${}\".format(initial_wealth))\n",
    "print(\"Final wealth: ${}\".format(s.wealth))\n",
    "print(\"Annualized return: {}\".format(ar))\n",
    "print(\"Time: {}s\".format(int(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Run simulation where constantly rebalance investments\n",
    "start = time.time()\n",
    "s = SimulationEnv(initial_wealth, stocks, \"data/djia_20000101_20171101/\", \"2000-01-01\", \"2017-11-01\", NaiveBuyHold, Dummy, True)\n",
    "s.setup_params(agent_args={})\n",
    "s.run()\n",
    "\n",
    "years = 17. + 11./12\n",
    "ar = ((s.wealth)/initial_wealth)**(1/years) - 1\n",
    "end = time.time()\n",
    "\n",
    "print(\"Initial wealth: ${}\".format(initial_wealth))\n",
    "print(\"Final wealth: ${}\".format(s.wealth))\n",
    "print(\"Annualized return: {}\".format(ar))\n",
    "print(\"Time: {}s\".format(int(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Run simulation where constantly rebalance investments\n",
    "start = time.time()\n",
    "s = SimulationEnv(initial_wealth, stocks, \"data/djia_20150101_20171101/\", \"2015-01-01\", \"2017-11-01\", ConstantRebalancer, Dummy, True)\n",
    "s.setup_params(agent_args={})\n",
    "s.run()\n",
    "\n",
    "years = 2. + 11./12\n",
    "ar = ((s.wealth)/initial_wealth)**(1/years) - 1\n",
    "end = time.time()\n",
    "\n",
    "print(\"Initial wealth: ${}\".format(initial_wealth))\n",
    "print(\"Final wealth: ${}\".format(s.wealth))\n",
    "print(\"Annualized return: {}\".format(ar))\n",
    "print(\"Time: {}s\".format(int(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Run simulation where constantly rebalance investments\n",
    "start = time.time()\n",
    "s = SimulationEnv(initial_wealth, stocks, \"data/djia_20000101_20171101/\", \"2000-01-01\", \"2017-11-01\", ConstantRebalancer, Dummy, True)\n",
    "s.setup_params(expert_args={\"eta\": -0.01})\n",
    "s.run()\n",
    "\n",
    "years = 17. + 11./12\n",
    "ar = ((s.wealth)/initial_wealth)**(1/years) - 1\n",
    "end = time.time()\n",
    "\n",
    "print(\"Initial wealth: ${}\".format(initial_wealth))\n",
    "print(\"Final wealth: ${}\".format(s.wealth))\n",
    "print(\"Annualized return: {}\".format(ar))\n",
    "print(\"Time: {}s\".format(int(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Run a simulation with Hedge, each expert is a proxy for buying a given stock\n",
    "start = time.time()\n",
    "\n",
    "s = SimulationEnv(initial_wealth, stocks, \"data/djia_20150101_20171101/\", \"2015-01-01\", \"2017-11-01\", EG, Dummy, True)\n",
    "s.setup_params(agent_args = {\"eta\": -0.01})\n",
    "s.run(log=True, logpath=\"logs\")\n",
    "\n",
    "years = 2. + 11./12\n",
    "ar = ((s.wealth)/initial_wealth)**(1/years) - 1\n",
    "end = time.time()\n",
    "\n",
    "print \"Initial wealth: ${}\".format(initial_wealth)\n",
    "print \"Final wealth: ${}\".format(s.wealth)\n",
    "print \"Annualized return: {}\".format(ar)\n",
    "print \"Time: {}s\".format(int(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Run a simulation with Hedge, each expert is a proxy for buying a given stock\n",
    "start = time.time()\n",
    "\n",
    "s = SimulationEnv(initial_wealth, stocks, \"data/djia_20000101_20171101/\", \"2000-01-01\", \"2017-11-01\", EG, Dummy, True)\n",
    "s.setup_params(agent_args = {\"eta\": -0.01})\n",
    "s.run()\n",
    "\n",
    "years = 17. + 11./12\n",
    "ar = ((s.wealth)/initial_wealth)**(1/years) - 1\n",
    "end = time.time()\n",
    "\n",
    "print \"Initial wealth: ${}\".format(initial_wealth)\n",
    "print \"Final wealth: ${}\".format(s.wealth)\n",
    "print \"Annualized return: {}\".format(ar)\n",
    "print \"Time: {}s\".format(int(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Run a simulation with Hedge, each expert is a proxy for buying a given stock\n",
    "\n",
    "s = SimulationEnv(initial_wealth, stocks, \"data/djia_20150101_20171101/\", \"2015-01-01\", \"2017-11-01\", EGRecent, Dummy, True)\n",
    "s.setup_params(agent_args = {\"eta\": -0.01, \"n\": 100})\n",
    "s.run()\n",
    "\n",
    "years = 2. + 11./12\n",
    "ar = ((s.wealth)/initial_wealth)**(1/years) - 1\n",
    "end = time.time()\n",
    "\n",
    "print \"Initial wealth: ${}\".format(initial_wealth)\n",
    "print \"Final wealth: ${}\".format(s.wealth)\n",
    "print \"Annualized return: {}\".format(ar)\n",
    "print \"Time: {}s\".format(int(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Run a simulation with Hedge, each expert is a proxy for buying a given stock\n",
    "\n",
    "s = SimulationEnv(initial_wealth, stocks, \"data/djia_20000101_20171101/\", \"2000-01-01\", \"2017-11-01\", EGRecent, Dummy, True)\n",
    "s.setup_params(agent_args = {\"eta\": -0.01, \"n\": 750})\n",
    "s.run()\n",
    "\n",
    "years = 17. + 11./12\n",
    "ar = ((s.wealth)/initial_wealth)**(1/years) - 1\n",
    "end = time.time()\n",
    "\n",
    "print \"Initial wealth: ${}\".format(initial_wealth)\n",
    "print \"Final wealth: ${}\".format(s.wealth)\n",
    "print \"Annualized return: {}\".format(ar)\n",
    "print \"Time: {}s\".format(int(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Run simulation where we just buy and hold all stocks in equal amounts\n",
    "start = time.time()\n",
    "s = SimulationEnv(initial_wealth, stocks, \"data/djia_20150101_20171101/\", \"2015-01-01\", \"2017-11-01\", NaiveBuyHold, Dummy, True)\n",
    "s.setup_params(expert_args={})\n",
    "s.run()\n",
    "\n",
    "years = 2. + 11./12\n",
    "ar = ((s.wealth)/initial_wealth)**(1/years) - 1\n",
    "end = time.time()\n",
    "\n",
    "print \"Initial wealth: ${}\".format(initial_wealth)\n",
    "print \"Final wealth: ${}\".format(s.wealth)\n",
    "print \"Annualized return: {}\".format(ar)\n",
    "print \"Time: {}s\".format(int(end-start))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Run simulation where we just buy and hold all stocks in equal amounts\n",
    "start = time.time()\n",
    "s = SimulationEnv(initial_wealth, stocks, \"data/djia_20000101_20171101/\", \"2000-01-01\", \"2017-11-01\", NaiveBuyHold, Dummy, True)\n",
    "s.setup_params(expert_args={})\n",
    "s.run()\n",
    "\n",
    "years = 17. + 11./12\n",
    "ar = ((s.wealth)/initial_wealth)**(1/years) - 1\n",
    "end = time.time()\n",
    "\n",
    "print \"Initial wealth: ${}\".format(initial_wealth)\n",
    "print \"Final wealth: ${}\".format(s.wealth)\n",
    "print \"Annualized return: {}\".format(ar)\n",
    "print \"Time: {}s\".format(int(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Run simulation where we each expert only recommends to buy when the price crosses 0.5 standard deviations below the 10-day moving average. \n",
    "## Otherwise doesn't do anything\n",
    "## Sell position when price gets above 0.5 standard deviations below the 10-day MA\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "s = SimulationEnv(initial_wealth, stocks, \"data/djia_20150101_20171101/\", \"2015-01-01\", \"2017-11-01\", EG, MeanReversion, True)\n",
    "\n",
    "s.setup_params(\n",
    "    agent_args={\"eta\": -0.01},\n",
    "    expert_args={\"window_size\": 10, \"threshold\": .5}\n",
    ")\n",
    "\n",
    "s.run()\n",
    "end = time.time()\n",
    "years = 2. + 11./12\n",
    "ar = ((s.wealth)/initial_wealth)**(1/years) - 1\n",
    "\n",
    "print \"Initial wealth: ${}\".format(initial_wealth)\n",
    "print \"Final wealth: ${}\".format(s.wealth)\n",
    "print \"Annualized return: {}\".format(ar)\n",
    "print \"Time: {}s\".format(int(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "start = time.time()\n",
    "\n",
    "s = SimulationEnv(initial_wealth, stocks, \"data/djia_20000101_20171101/\", \"2000-01-01\", \"2017-11-01\", EG, MeanReversion, True)\n",
    "\n",
    "s.setup_params(\n",
    "    agent_args={\"eta\": -0.01},\n",
    "    expert_args={\"window_size\": 10, \"threshold\": .5}\n",
    ")\n",
    "\n",
    "s.run()\n",
    "end = time.time()\n",
    "years = 17. + 11./12\n",
    "ar = ((s.wealth)/initial_wealth)**(1/years) - 1\n",
    "\n",
    "print \"Initial wealth: ${}\".format(initial_wealth)\n",
    "print \"Final wealth: ${}\".format(s.wealth)\n",
    "print \"Annualized return: {}\".format(ar)\n",
    "print \"Time: {}s\".format(int(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "start = time.time()\n",
    "\n",
    "s = SimulationEnv(initial_wealth, stocks, \"data/djia_20000101_20171101/\", \"2000-01-01\", \"2017-11-01\", EGRecent, MeanReversion, True)\n",
    "\n",
    "s.setup_params(\n",
    "    agent_args={\"eta\": -0.01, \"n\": 1250},\n",
    "    expert_args={\"window_size\": 10, \"threshold\": .5}\n",
    ")\n",
    "\n",
    "s.run()\n",
    "end = time.time()\n",
    "years = 17. + 11./12\n",
    "ar = ((s.wealth)/initial_wealth)**(1/years) - 1\n",
    "\n",
    "print \"Initial wealth: ${}\".format(initial_wealth)\n",
    "print \"Final wealth: ${}\".format(s.wealth)\n",
    "print \"Annualized return: {}\".format(ar)\n",
    "print \"Time: {}s\".format(int(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "s = SimulationEnv(initial_wealth, stocks, \"data/djia_20150101_20171101/\", \"2015-01-01\", \"2017-11-01\", EG, Momentum, True)\n",
    "\n",
    "years = 2. + 11./12\n",
    "s.setup_params(\n",
    "    agent_args={\"eta\": -0.01},\n",
    "    expert_args={\"window_size\": 10, \"threshold\": 2.5}\n",
    ")\n",
    "\n",
    "s.run()\n",
    "end = time.time()\n",
    "\n",
    "ar = ((s.wealth)/initial_wealth)**(1/years) - 1\n",
    "\n",
    "print \"Initial wealth: ${}\".format(initial_wealth)\n",
    "print \"Final wealth: ${}\".format(s.wealth)\n",
    "print \"Annualized return: {}\".format(ar)\n",
    "print \"Time: {}s\".format(int(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "s = SimulationEnv(initial_wealth, stocks, \"data/djia_20000101_20171101/\", \"2000-01-01\", \"2017-11-01\", EG, Momentum, True)\n",
    "\n",
    "years = 17. + 11./12\n",
    "s.setup_params(\n",
    "    agent_args={\"eta\": -0.01},\n",
    "    expert_args={\"window_size\": 10, \"threshold\": 2.5}\n",
    ")\n",
    "\n",
    "s.run()\n",
    "end = time.time()\n",
    "\n",
    "ar = ((s.wealth)/initial_wealth)**(1/years) - 1\n",
    "\n",
    "print \"Initial wealth: ${}\".format(initial_wealth)\n",
    "print \"Final wealth: ${}\".format(s.wealth)\n",
    "print \"Annualized return: {}\".format(ar)\n",
    "print \"Time: {}s\".format(int(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "s = SimulationEnv(initial_wealth, stocks, \"data/djia_20000101_20171101/\", \"2000-01-01\", \"2017-11-01\", EGRecent, Momentum, True)\n",
    "\n",
    "years = 17. + 11./12\n",
    "s.setup_params(\n",
    "    agent_args={\"eta\": -0.001, \"n\": 500},\n",
    "    expert_args={\"window_size\": 10, \"threshold\": 2.5}\n",
    ")\n",
    "\n",
    "s.run()\n",
    "end = time.time()\n",
    "\n",
    "ar = ((s.wealth)/initial_wealth)**(1/years) - 1\n",
    "\n",
    "print \"Initial wealth: ${}\".format(initial_wealth)\n",
    "print \"Final wealth: ${}\".format(s.wealth)\n",
    "print \"Annualized return: {}\".format(ar)\n",
    "print \"Time: {}s\".format(int(end-start))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
